{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24C9Iu9F4w32"
      },
      "source": [
        "# Lab 5: Logistic Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCYoCkgv4w39"
      },
      "source": [
        "Author: Seungjae Lee (이승재)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D4vOLwb4w3-"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    We use elemental PyTorch to implement linear regression here. However, in most actual applications, abstractions such as <code>nn.Module</code> or <code>nn.Linear</code> are used. You can see those implementations near the end of this notebook.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r56n9dp54w3-"
      },
      "source": [
        "## Reminder: Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b8pAKip4w3_"
      },
      "source": [
        "### Hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13JnNZdR4w3_"
      },
      "source": [
        "$$ H(X) = \\frac{1}{1+e^{-W^T X}} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0a7X3aE4w3_"
      },
      "source": [
        "### Cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "795V5diP4w4A"
      },
      "source": [
        "$$ cost(W) = -\\frac{1}{m} \\sum y \\log\\left(H(x)\\right) + (1-y) \\left( \\log(1-H(x) \\right) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95nGje3j4w4A"
      },
      "source": [
        " - If $y \\simeq H(x)$, cost is near 0.\n",
        " - If $y \\neq H(x)$, cost is high."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-nyWNBE4w4B"
      },
      "source": [
        "### Weight Update via Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2vgBu1A4w4B"
      },
      "source": [
        "$$ W := W - \\alpha \\frac{\\partial}{\\partial W} cost(W) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDkPHF-d4w4B"
      },
      "source": [
        " - $\\alpha$: Learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8pHntbt4w4B"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7X-KIEvO4w4C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DL-GNaF4w4C",
        "outputId": "a7eaeb76-b7c4-43e5-c4a0-47b4a078369f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc324ab8790>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# For reproducibility\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI7YMVuz4w4D"
      },
      "source": [
        "## Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cyFePWkt4w4D"
      },
      "outputs": [],
      "source": [
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY6K3TEu4w4E"
      },
      "source": [
        "Consider the following classification problem: given the number of hours each student spent watching the lecture and working in the code lab, predict whether the student passed or failed a course. For example, the first (index 0) student watched the lecture for 1 hour and spent 2 hours in the lab session ([1, 2]), and ended up failing the course ([0])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3hUBEs2G4w4E"
      },
      "outputs": [],
      "source": [
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3G1svl84w4E"
      },
      "source": [
        "As always, we need these data to be in `torch.Tensor` format, so we convert them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPCzipLx4w4E",
        "outputId": "7c360e47-14f3-4716-c94f-7d4c50c2336f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 2])\n",
            "torch.Size([6, 1])\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t-deAyw4w4E"
      },
      "source": [
        "## Computing the Hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyX0mEGE4w4E"
      },
      "source": [
        "$$ H(X) = \\frac{1}{1+e^{-W^T X}} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2ll5yGY4w4F"
      },
      "source": [
        "PyTorch has a `torch.exp()` function that resembles the exponential function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mDumuMd4w4F",
        "outputId": "f29c66f9-ea87-4ae8-cf4a-d1ccf30f4286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e^1 equals:  tensor([2.7183])\n"
          ]
        }
      ],
      "source": [
        "print('e^1 equals: ', torch.exp(torch.FloatTensor([1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgy4YpNJ4w4F"
      },
      "source": [
        "We can use it to compute the hypothesis function conveniently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HFs7aR9E4w4F"
      },
      "outputs": [],
      "source": [
        "W = torch.zeros((2, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KtTEEh-24w4F"
      },
      "outputs": [],
      "source": [
        "hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XBCkxmr4w4G",
        "outputId": "1640f72d-e71d-4322-fddf-9cbacece7917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<MulBackward0>)\n",
            "torch.Size([6, 1])\n"
          ]
        }
      ],
      "source": [
        "print(hypothesis)\n",
        "print(hypothesis.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GScJRlkg4w4G"
      },
      "source": [
        "Or, we could use `torch.sigmoid()` function! This resembles the sigmoid function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04OLPtMw4w4G",
        "outputId": "dd58ff59-005e-45f6-d3c6-78fc1aeaf953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/(1+e^{-1}) equals:  tensor([0.7311])\n"
          ]
        }
      ],
      "source": [
        "print('1/(1+e^{-1}) equals: ', torch.sigmoid(torch.FloatTensor([1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-Ldc2za4w4G"
      },
      "source": [
        "Now, the code for hypothesis function is cleaner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "woAxyCVm4w4G"
      },
      "outputs": [],
      "source": [
        "hypothesis = torch.sigmoid(x_train.matmul(W) + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSLo0tMq4w4G",
        "outputId": "ee5f0142-6290-4ddc-c924-5b73ddb0eec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([6, 1])\n"
          ]
        }
      ],
      "source": [
        "print(hypothesis)\n",
        "print(hypothesis.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-2XjGho4w4G"
      },
      "source": [
        "## Computing the Cost Function (Low-level)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4By6ZkIj4w4G"
      },
      "source": [
        "$$ cost(W) = -\\frac{1}{m} \\sum y \\log\\left(H(x)\\right) + (1-y) \\left( \\log(1-H(x) \\right) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYq-zWzz4w4G"
      },
      "source": [
        "We want to measure the difference between `hypothesis` and `y_train`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00qkR3_A4w4H",
        "outputId": "beb93e9b-8121-4d7c-c7d4-6de257993f46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<SigmoidBackward0>)\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n"
          ]
        }
      ],
      "source": [
        "print(hypothesis)\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS3nmczw4w4H"
      },
      "source": [
        "For one element, the loss can be computed as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX3Aigsn4w4H",
        "outputId": "a18270e0-c599-4f4c-b68b-f9d7f6ea3e3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6931], grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "-(y_train[0] * torch.log(hypothesis[0]) + \n",
        "  (1 - y_train[0]) * torch.log(1 - hypothesis[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUlchP6T4w4H"
      },
      "source": [
        "To compute the losses for the entire batch, we can simply input the entire vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV8tl0Wr4w4H",
        "outputId": "5f0d3ed8-0694-4718-cafc-bd7b533b40db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931]], grad_fn=<NegBackward0>)\n"
          ]
        }
      ],
      "source": [
        "losses = -(y_train * torch.log(hypothesis) + \n",
        "           (1 - y_train) * torch.log(1 - hypothesis))\n",
        "print(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vlYUNvA4w4H"
      },
      "source": [
        "Then, we just `.mean()` to take the mean of these individual losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8ORZH8T4w4H",
        "outputId": "a822c849-3cbb-4b15-e575-88f51147bf25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6931, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "cost = losses.mean()\n",
        "print(cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hdSVGHf4w4I"
      },
      "source": [
        "## Computing the Cost Function with `F.binary_cross_entropy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz8-SoqG4w4I"
      },
      "source": [
        "In reality, binary classification is used so often that PyTorch has a simple function called `F.binary_cross_entropy` implemented to lighten the burden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQQQIaGq4w4I",
        "outputId": "3951750d-c218-4bf9-a553-fee6f76b7695"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "F.binary_cross_entropy(hypothesis, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw5EPsR_4w4I"
      },
      "source": [
        "## Training with Low-level Binary Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7MyZbJDN4w4I"
      },
      "outputs": [],
      "source": [
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeBkFvRH4w4I",
        "outputId": "4377b6ed-2c98-44e7-ac5c-b3c949f24904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.693147\n",
            "Epoch  100/1000 Cost: 0.134722\n",
            "Epoch  200/1000 Cost: 0.080643\n",
            "Epoch  300/1000 Cost: 0.057900\n",
            "Epoch  400/1000 Cost: 0.045300\n",
            "Epoch  500/1000 Cost: 0.037261\n",
            "Epoch  600/1000 Cost: 0.031673\n",
            "Epoch  700/1000 Cost: 0.027556\n",
            "Epoch  800/1000 Cost: 0.024394\n",
            "Epoch  900/1000 Cost: 0.021888\n",
            "Epoch 1000/1000 Cost: 0.019852\n"
          ]
        }
      ],
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((2, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n",
        "    cost = -(y_train * torch.log(hypothesis) + \n",
        "             (1 - y_train) * torch.log(1 - hypothesis)).mean()\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyTLX53v4w4I"
      },
      "source": [
        "## Training with `F.binary_cross_entropy`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAYaLMAj4w4I",
        "outputId": "ddf59c68-8975-4a48-e67a-a531084cf345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.693147\n",
            "Epoch  100/1000 Cost: 0.134722\n",
            "Epoch  200/1000 Cost: 0.080643\n",
            "Epoch  300/1000 Cost: 0.057900\n",
            "Epoch  400/1000 Cost: 0.045300\n",
            "Epoch  500/1000 Cost: 0.037261\n",
            "Epoch  600/1000 Cost: 0.031672\n",
            "Epoch  700/1000 Cost: 0.027556\n",
            "Epoch  800/1000 Cost: 0.024394\n",
            "Epoch  900/1000 Cost: 0.021888\n",
            "Epoch 1000/1000 Cost: 0.019852\n"
          ]
        }
      ],
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((2, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DByKpPt4w4I"
      },
      "source": [
        "## Loading Real Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5FVVcqAk4w4J"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/d_competition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTkMzls2_KV9",
        "outputId": "036d7184-f831-4f25-eacc-b8b1141a555e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/d_competition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PymmLLtD4w4J"
      },
      "outputs": [],
      "source": [
        "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
        "x_data = xy[:, 0:-1]\n",
        "y_data = xy[:, [-1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgF4a5Lw4w4J",
        "outputId": "3da17543-6abf-46ad-8ac3-6775c6bbb861"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.2941,  0.4874,  0.1803, -0.2929,  0.0000,  0.0015, -0.5312, -0.0333],\n",
            "        [-0.8824, -0.1457,  0.0820, -0.4141,  0.0000, -0.2072, -0.7669, -0.6667],\n",
            "        [-0.0588,  0.8392,  0.0492,  0.0000,  0.0000, -0.3055, -0.4927, -0.6333],\n",
            "        [-0.8824, -0.1055,  0.0820, -0.5354, -0.7778, -0.1624, -0.9240,  0.0000],\n",
            "        [ 0.0000,  0.3769, -0.3443, -0.2929, -0.6028,  0.2846,  0.8873, -0.6000]])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ]
        }
      ],
      "source": [
        "print(x_train[0:5])\n",
        "print(y_train[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmhddnjU_Jhg",
        "outputId": "da8bca44-52c6-4b70-a1f4-53e42bad314d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEFVtifm4w4J"
      },
      "source": [
        "## Training with Real Data using low-level Binary Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZjlYAyn4w4J",
        "outputId": "a2901ad6-9356-4edf-83b0-f1a59b861c01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/100 Cost: 0.693147\n",
            "Epoch   10/100 Cost: 0.572727\n",
            "Epoch   20/100 Cost: 0.539493\n",
            "Epoch   30/100 Cost: 0.519708\n",
            "Epoch   40/100 Cost: 0.507066\n",
            "Epoch   50/100 Cost: 0.498539\n",
            "Epoch   60/100 Cost: 0.492549\n",
            "Epoch   70/100 Cost: 0.488209\n",
            "Epoch   80/100 Cost: 0.484985\n",
            "Epoch   90/100 Cost: 0.482543\n",
            "Epoch  100/100 Cost: 0.480661\n"
          ]
        }
      ],
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((8, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1)\n",
        "\n",
        "nb_epochs = 100\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n",
        "    cost = -(y_train * torch.log(hypothesis) + (1 - y_train) * torch.log(1 - hypothesis)).mean()\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 10번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAdP38Fi4w4J"
      },
      "source": [
        "## Training with Real Data using `F.binary_cross_entropy`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrPi-HVt4w4J",
        "outputId": "e1269608-e273-46b2-881d-cf6197eadeef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/100 Cost: 0.693147\n",
            "Epoch   10/100 Cost: 0.572727\n",
            "Epoch   20/100 Cost: 0.539493\n",
            "Epoch   30/100 Cost: 0.519708\n",
            "Epoch   40/100 Cost: 0.507066\n",
            "Epoch   50/100 Cost: 0.498539\n",
            "Epoch   60/100 Cost: 0.492549\n",
            "Epoch   70/100 Cost: 0.488209\n",
            "Epoch   80/100 Cost: 0.484985\n",
            "Epoch   90/100 Cost: 0.482543\n",
            "Epoch  100/100 Cost: 0.480661\n"
          ]
        }
      ],
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((8, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1)\n",
        "\n",
        "nb_epochs = 100\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 10번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ry1dxiW4w4J"
      },
      "source": [
        "## Checking the Accuracy our our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FR77E-64w4J"
      },
      "source": [
        "After we finish training the model, we want to check how well our model fits the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99D7Uoiw4w4J",
        "outputId": "b5746259-d098-429d-e0dc-baa334dac226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4103],\n",
            "        [0.9242],\n",
            "        [0.2300],\n",
            "        [0.9411],\n",
            "        [0.1772]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ],
      "source": [
        "hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
        "print(hypothesis[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijLvT_vp4w4J"
      },
      "source": [
        "We can change **hypothesis** (real number from 0 to 1) to **binary predictions** (either 0 or 1) by comparing them to 0.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vmrROXZ4w4J",
        "outputId": "0b59ac9a-407d-4cb2-f521-93984e63df83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False],\n",
            "        [ True],\n",
            "        [False],\n",
            "        [ True],\n",
            "        [False]])\n"
          ]
        }
      ],
      "source": [
        "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "print(prediction[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1xb6a5l4w4K"
      },
      "source": [
        "Then, we compare it with the correct labels `y_train`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbZH9Qc14w4K",
        "outputId": "c3fec9a1-e963-44d5-bed6-e0284e21432b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False],\n",
            "        [ True],\n",
            "        [False],\n",
            "        [ True],\n",
            "        [False]])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ]
        }
      ],
      "source": [
        "print(prediction[:5])\n",
        "print(y_train[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijqHXSwu4w4K",
        "outputId": "a2f449e1-8f8a-4429-9155-db81c36438e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True]])\n"
          ]
        }
      ],
      "source": [
        "correct_prediction = prediction.float() == y_train\n",
        "print(correct_prediction[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzBozV9j4w4K"
      },
      "source": [
        "Finally, we can calculate the accuracy by counting the number of correct predictions and dividng by total number of predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYsGAhF_4w4K",
        "outputId": "054c90de-1929-47ef-b2e0-a06b0f363f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has an accuracy of 76.68% for the training set.\n"
          ]
        }
      ],
      "source": [
        "accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
        "print('The model has an accuracy of {:2.2f}% for the training set.'.format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h27sS9rv4w4K"
      },
      "source": [
        "## Optional: High-level Implementation with `nn.Module`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XYwMT38F4w4K"
      },
      "outputs": [],
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(8, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "iUDroRmB4w4K"
      },
      "outputs": [],
      "source": [
        "model = BinaryClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg7acIuy4w4K",
        "outputId": "45ab2030-d462-4183-95ba-94468a043703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/100 Cost: 0.704829 Accuracy 45.72%\n",
            "Epoch   10/100 Cost: 0.572392 Accuracy 67.59%\n",
            "Epoch   20/100 Cost: 0.539563 Accuracy 73.25%\n",
            "Epoch   30/100 Cost: 0.520041 Accuracy 75.89%\n",
            "Epoch   40/100 Cost: 0.507561 Accuracy 76.15%\n",
            "Epoch   50/100 Cost: 0.499125 Accuracy 76.42%\n",
            "Epoch   60/100 Cost: 0.493177 Accuracy 77.21%\n",
            "Epoch   70/100 Cost: 0.488846 Accuracy 76.81%\n",
            "Epoch   80/100 Cost: 0.485612 Accuracy 76.28%\n",
            "Epoch   90/100 Cost: 0.483146 Accuracy 76.55%\n",
            "Epoch  100/100 Cost: 0.481234 Accuracy 76.81%\n"
          ]
        }
      ],
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "nb_epochs = 100\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "        correct_prediction = prediction.float() == y_train\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format(\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
        "        ))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SvQXJIzG_j-O"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "lab-05_logistic_classification.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}